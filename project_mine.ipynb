{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Git submission"
      ],
      "metadata": {
        "id": "uViq1t3Baim_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "gdrive_path='/content/gdrive/MyDrive'\n",
        "\n",
        "# This will mount your google drive under 'MyDrive'\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "# In order to access the files in this notebook we have to navigate to the correct folder\n",
        "os.chdir(gdrive_path)\n",
        "# Check manually if all files are present\n",
        "print(sorted(os.listdir()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOlOz4zprEJT",
        "outputId": "76f1c6d7-5a87-4872-bd8f-7a94a0748cb3"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "['.git', 'Colab Notebooks', 'Flicker8k_Dataset', 'German', 'Image Processing', 'ImageCaptioning', 'additional_homework', 'datasets', 'descriptions.txt', 'epam', 'homework_09', 'homework_10', 'output', 'project_files', 'save.txt', 'save.txt.pub', 'test.pkl', 'text']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "eJaIycNoogD3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow\n",
        "import keras\n",
        "from os import listdir\n",
        "from pickle import dump\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.models import Model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(directory):\n",
        "\n",
        "\tmodel = VGG16()\n",
        "\n",
        "\tmodel = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
        "\n",
        "\tprint(model.summary())\n",
        "\n",
        "\tfeatures = {}\n",
        "\n",
        "\tfor name in listdir(directory):\n",
        "\t\tfilename = directory + '/' + name\n",
        "\t\timage = load_img(filename, target_size=(224, 224))\n",
        "\t\timage = img_to_array(image)\n",
        "\t\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\t\timage = preprocess_input(image)\n",
        "\t\tfeature = model.predict(image, verbose=0)\n",
        "\t\timage_id = name.split('.')[0]\n",
        "\t\tfeatures[image_id] = feature\n",
        "\t\tprint('>%s' % name)\n",
        "\treturn features"
      ],
      "metadata": {
        "id": "DIMogWb0rDP4"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory = 'Flickr8k_Dataset'\n",
        "features = extract_features(directory)\n",
        "print('Extracted Features: %d' % len(features))\n",
        "# save to file\n",
        "#dump(features, open('features.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "sSyI2-yWN538"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'text/Flickr8k.token.txt'\n",
        "\n",
        "def load_doc(filename):\n",
        "\tfile = open(filename, 'r')\n",
        "\ttext = file.read()\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "doc = load_doc(filename)"
      ],
      "metadata": {
        "id": "17vCDEVSRCXa"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_descriptions(doc):\n",
        "\tmapping = {}\n",
        "\n",
        "\tfor line in doc.split('\\n'):\n",
        "\n",
        "\t\ttokens = line.split()\n",
        "\t\tif len(line) < 2:\n",
        "\t\t\tcontinue\n",
        "\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\n",
        "\t\timage_id = image_id.split('.')[0]\n",
        "\t\timage_desc = ' '.join(image_desc)\n",
        "\t\tif image_id not in mapping:\n",
        "\t\t\tmapping[image_id] = list()\n",
        "\t\tmapping[image_id].append(image_desc)\n",
        "\treturn mapping\n",
        "\n",
        "\n",
        "descriptions = load_descriptions(doc)\n",
        "print('Loaded: %d ' % len(descriptions))\n",
        "print(descriptions[\"1358089136_976e3d2e30\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNlQUXDtQz8_",
        "outputId": "663c400b-526e-4d75-adcf-0c13868e54a5"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: 8092 \n",
            "['A boy sand surfing down a hill', 'A man is attempting to surf down a hill made of sand on a sunny day .', 'A man is sliding down a huge sand dune on a sunny day .', 'A man is surfing down a hill of sand .', 'A young man in shorts and t-shirt is snowboarding under a bright blue sky .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def tokenize(text):\n",
        "\n",
        "    return [s.lower() for s in re.split(r'\\W+', text) if len(s) > 2]\n",
        "\n",
        "freqs = Counter()\n",
        "\n",
        "# Tokenize and count occurrences\n",
        "all_tokens = []\n",
        "for descs in descriptions.values():\n",
        "    for sentence in descs:\n",
        "        tokens = tokenize(sentence)\n",
        "        all_tokens.extend(tokens)\n",
        "\n",
        "word_freqs = Counter(all_tokens)\n",
        "specials = [\"<pad>\", \"<start>\", \"<end>\", \"<unk>\"]\n",
        "#remove all words that appear once\n",
        "vocab = specials + [word for word, count in word_freqs.items() if count >= 2]\n",
        "\n",
        "word_to_index = {word: idx for idx, word in enumerate(vocab)}\n",
        "\n",
        "max_length = max(len(tokenize(desc)) for descs in descriptions.values() for desc in descs) + 2\n",
        "print(max_length)\n",
        "def encode_sentence(sentence, word_to_index, max_length):\n",
        "\n",
        "    tokens = tokenize(sentence)\n",
        "    encoded = [word_to_index.get(\"<start>\")]\n",
        "    for token in tokens:\n",
        "        if token in word_to_index:\n",
        "            encoded.append(word_to_index[token])\n",
        "        else:\n",
        "            encoded.append(word_to_index.get(\"<unk>\"))\n",
        "    encoded.append(word_to_index.get(\"<end>\"))\n",
        "    while len(encoded) < max_length:\n",
        "        encoded.append(word_to_index.get(\"<pad>\"))\n",
        "\n",
        "    return encoded\n",
        "\n",
        "encoded_descriptions = {}\n",
        "for image_id, descs in descriptions.items():\n",
        "    encoded_descriptions[image_id] = [encode_sentence(sentence, word_to_index, max_length) for sentence in descs]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXsddz_zShAt",
        "outputId": "51f645a2-56c7-4683-ac6f-6a4761900a3f"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoded_descriptions[\"1358089136_976e3d2e30\"])\n",
        "# # save descriptions to file, one per line\n",
        "# def save_descriptions(descriptions, filename):\n",
        "# \tlines = list()\n",
        "# \tfor key, desc_list in descriptions.items():\n",
        "# \t\tfor desc in desc_list:\n",
        "# \t\t\tlines.append(key + ' ' + desc)\n",
        "# \tdata = '\\n'.join(lines)\n",
        "# \tfile = open(filename, 'w')\n",
        "# \tfile.write(data)\n",
        "# \tfile.close()\n",
        "\n",
        "# # save descriptions\n",
        "# save_descriptions(descriptions, 'descriptions.txt')"
      ],
      "metadata": {
        "id": "QM0n4kyEShKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import load\n",
        "def load_photo_features(filename, dataset):\n",
        "\tall_features = load(open(filename, 'rb'))\n",
        "\tfeatures = {k: all_features[k] for k in dataset}\n",
        "\treturn features"
      ],
      "metadata": {
        "id": "ehBHgt2YS7iA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ghkQwCraTgeP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}